# RNN/CNN-based Natural Language Inference

### Datasets:
* Train and Parameter-tuning RNN & CNN on SNLI
* Test RNN & CNN on MultiNLI

> [NLP_HW2_CNN.ipynb](docs/https://github.com/hb1500/RNN-CNN-based-Natural-Language-Inference/blob/master/NLP_HW2_CNN.ipynb) includes: 
* 2-layers 1-D CNN model
* training process
* paramter-tuning(hidden size, kernel size)
* evaludation on MNLI by genres
* 3 correct/incorrect samples

> [NLP_HW2_RNN.ipynb](docs/https://github.com/hb1500/RNN-CNN-based-Natural-Language-Inference/blob/master/NLP_HW2_RNN.ipynb) includes:
* single-layer bi-directional GRU model 
* training process 
* paramter-tuning(hidden size, dropout rate), 
* evaludation on MNLI by genres
* 3 correct/incorrect samples
* Bonus: Fine-tuning on MNLI by genres

> Results folder(docs/https://github.com/hb1500/RNN-CNN-based-Natural-Language-Inference/tree/master/results) includes:
* all intermediate training, validation accuracy and loss record 
* RNN plots: loss, train, validation curves by hidden size and dropout
* RNN plots: loss, train, validation curves by hidden size and kernel size
